---
editor_options:
  chunk_output_type: console
---

# NOTES

-   This file is *not* included in the [source package](https://r-pkgs.org/structure.html#sec-source-package) because of the [`.nopurl` suffix in its
    filename](https://pkgpurl.rpkg.dev/reference/purl_rmd.html#-rmd-files-excluded-from-purling).

-   The chunks below have to be manually executed in order to regenerate the package data.

-   Although the datasets below are saved as ["internal data" in `R/sysdata.rda`](https://r-pkgs.org/data.html#sec-data-sysdata), they can still be exported and
    documented (by documenting the dataset's quoted name in the main `.Rmd` source file -- which only works when the dataset is also `@export`ed), something
    [not explicitly mentioned](https://coolbutuseless.github.io/2018/12/10/r-packages-internal-and-external-data/) in the book [R
    Packages](https://r-pkgs.org/data.html#sec-data-data). To do so, you first need to manually add the `export()` directive in the NAMESPACE file since
    roxygen2 won't add it automatically.

# Setup

```{r}
library(rlang,
        include.only = "%|%")
library(magrittr,
        include.only = c("%>%", "%<>%", "%T>%", "%!>%", "%$%"))
```

# Define data

## `col_names_nocodb_filled`

```{r}
col_names_nocodb_filled <- c("created_by",
                             "updated_by")
```

## `col_names_un`

UN world region variables

```{r}
col_names_un <- c("un_country_code",
                  "un_region_tier_1_code",
                  "un_region_tier_1_name",
                  "un_region_tier_2_code",
                  "un_region_tier_2_name",
                  "un_region_tier_3_code",
                  "un_region_tier_3_name",
                  "un_subregion")
```

## `data_codebook`

TODO:

-   Consider migrating the codebook to the qstnr questionnaire schema and using qstnr to process it.

NOTES:

-   In the following cases, a variable's prototype (`ptype`) has to be explicitly set in the raw `codebook.Rmd`:

    -   It's a floating point number. -\> Set `ptype = "numeric()"`.
    -   It's a complex number. -\> Set `ptype = "complex()"`.
    -   It's non-basic data type, i.e. a structure like a date. Set `ptype` to the proper value like `ptype = "vctrs::new_date()"`.

```{r}
data_codebook <- {
  
  codebook <- pal::toml_read("data-raw/rdb_codebook.toml")
  
  c(codebook$`01_main`$item,
    codebook$`02_institutional`$`01_status`$item,
    codebook$`02_institutional`$`02_trigger`$item,
    codebook$`02_institutional`$`03_object`$item,
    codebook$`02_institutional`$`04_other`$item) |>
    purrr::map(~ tibble::tibble(variable_name = .x$variable_name %||% NA_character_,
                                variable_name_print = .x$variable_name_print %||% NA_character_,
                                variable_name_unnested = .x$variable_name_unnested %||% variable_name,
                                variable_name_unnested_print = .x$variable_name_unnested_print %||% variable_name_print,
                                variable_label = .x$variable_label %||% NA_character_,
                                is_multi_valued = isTRUE(.x$is_multi_valued),
                                is_nested = isTRUE(.x$is_nested),
                                applicability_constraint = .x$applicability_constraint %||% NA_character_,
                                variable_values = list(.x$variable_values %||% character()),
                                value_label_prefix = .x$value_label_prefix %||% NA_character_,
                                value_labels = list(.x$value_labels %||% character()),
                                value_label_suffix = .x$value_label_suffix %||% NA_character_,
                                value_default = list(.x$value_default),
                                value_scale = .x$value_scale %||% NA_character_,
                                ptype =
                                  .x$ptype |>
                                  pal::when(!is.null(.) ~ eval(parse(text = .)),
                                            ~ .) |>
                                  list(),
                                derived_from =
                                  .x$derived_from |>
                                  pal::when(is.null(.) ~ list(character()),
                                            is.character(.) ~ list(.),
                                            ~ .),
                                gen_fn = .x$gen_fn %||% NA_character_,
                                is_opt = isTRUE(.x$is_opt))) |>
    purrr::list_rbind() |>
    # infer missing prototypes
    dplyr::mutate(ptype = purrr::pmap(.l = list(is_multi_valued,
                                                is_nested,
                                                variable_values,
                                                value_labels,
                                                value_scale,
                                                ptype),
                                      .f = function(is_multi_valued,
                                                    is_nested,
                                                    variable_values,
                                                    value_labels,
                                                    value_scale,
                                                    ptype) {
                                        
                                        value_scale |>
                                          pal::when(!is.null(ptype) ~
                                                      ptype,
                                                    . == "undefined" || is_multi_valued || is_nested ~
                                                      list(),
                                                    . == "binary" && (length(value_labels) == 0L || all(is.logical(unlist(variable_values)))) ~
                                                      logical(),
                                                    . %in% c("nominal") && length(value_labels) == 0L ~
                                                      character(),
                                                    . %in% c("nominal", "binary", "ordinal_ascending", "ordinal_descending") ~
                                                      factor(levels = variable_values,
                                                             ordered = . %in% c("ordinal_ascending", "ordinal_descending")),
                                                    . %in% c("interval", "ratio") ~
                                                      integer())
                                      })) |>
    # integrity checks
    ## not NA
    assertr::assert(predicate = assertr::not_na,
                    variable_name,
                    variable_name_print,
                    variable_name_unnested,
                    variable_name_unnested_print,
                    variable_label,
                    value_scale,
                    is_multi_valued,
                    is_nested,
                    ptype,
                    is_opt) |>
    ## not empty string
    assertr::assert(predicate = \(x) !(x == ""),
                    variable_name,
                    variable_name_print,
                    variable_name_unnested,
                    variable_name_unnested_print,
                    variable_label,
                    value_scale)
}
```

## ISO Codes

NOTES:

-   ISO monetizes the standards itselves as well as derived datasets like the [Country Codes Collection](https://www.iso.org/publication/PUB500001.html) instead
    of offering open data APIs! ðŸ¤¬ So most open-source projects including the R package [ISOcodes](https://cran.r-project.org/package=ISOcodes) source their ISO
    3166 data from [Debian's `iso-codes` project](https://salsa.debian.org/iso-codes-team/iso-codes) which might deviate from the official standard and lack
    behind updates.

-   ISO 3166-1 does not specify the time dimensions of countries. It maintains only information with regard to their most recent status. A [period of
    validity](https://salsa.debian.org/iso-codes-team/iso-codes/-/issues/43) is only defined when a country is deleted from ISO 3166-1 and moved to ISO 3166-3.
    Thus, this information must be retrieved from another source.

    Noteworthy candidates for this include:

    -   The [*Territory Information System
        (TIS)*](https://www.gema.de/en/help/help-topics-for-creators/works-repertoire/submit-a-notification-for-your-works/what-are-tis-codes-where-can-i-find-information-on-the-territory-standard-tis/)
        by the [CISAC](https://en.wikipedia.org/wiki/Conf%C3%A9d%C3%A9ration_Internationale_des_Soci%C3%A9t%C3%A9s_d%27Auteurs_et_Compositeurs) which at first
        glance seems to be exactly what we're looking for. The latest revision can be downloaded
        [here](https://members.cisac.org/CisacPortal/documentPack20.do?method=detail&id=21). But as it turns out, it's tailored to the CISAC's specific needs
        and doesn't go back further than the 1990s. â˜¹

    -   The [*Standard Classification of Countries and Areas of Interest (SCCAI)*](https://www150.statcan.gc.ca/n1/en/catalogue/12-608-X) by Statistics Canada
        which includes a list of *Current and Historical Countries and Areas of Interest* that define a start and end date for each country/area. The latest
        version from 2019 is available [here](https://www.statcan.gc.ca/en/subjects/standard/sccai/2019/countries). Countries there are identified by a
        five-digit SCCAI code where the last three digit [correspond to the United Nations numeric code (NUM-3) for countries or
        areas](https://www.statcan.gc.ca/en/subjects/standard/sccai/2019/introduction). To get the ISO 3166-1 alpha-2 code, one can also simply join the data
        with the [main SCCAI 2019 data](https://www23.statcan.gc.ca/imdb/p3VD.pl?Function=getVD&TVD=1251826). Unfortunately, the precision of the provided start
        and end dates is only years, not actual dates. Also it's unclear when and how SCCAI gets updated, i.e. how well it'll be maintained in the future.

    -   The [Correlates of War](https://en.wikipedia.org/wiki/Correlates_of_War) project's [State System
        Membership](https://correlatesofwar.org/data-sets/state-system-membership/) dataset

    -   Wikidata!

    To verify periods of validity of countries, the following resources are useful:

    -   Wikipedia's [List of sovereign states by date of formation](https://en.wikipedia.org/wiki/List_of_sovereign_states_by_date_of_formation)
    -   Wikipedia's [List of former sovereign states](https://en.wikipedia.org/wiki/List_of_former_sovereign_states)
    -   Wikipedia's [List of national independence days](https://en.wikipedia.org/wiki/List_of_national_independence_days)

### `data_iso_3166_1`

ISO 3166-1 data, corrected and extended by unofficial information for countries which are not covered by the ISO standard yet. See also the [Differences between
SCCAI 2019 and ISO 3166-1:2013](https://www.statcan.gc.ca/en/subjects/standard/sccai/2019/sccai2019-iso3166-12013) for inspiration on name corrections.

```{r}
data_iso_3166_1 <-
  ISOcodes::ISO_3166_1 |>
  tibble::as_tibble() |>
  # convert column names to snake_case
  dplyr::rename_with(.cols = everything(),
                     .fn = snakecase::to_snake_case) |>
  # add `common_name` where it's currently missing
  # TODO: consider submitting PRs once [upstream issue #44](https://salsa.debian.org/iso-codes-team/iso-codes/-/issues/44) is answered
  dplyr::mutate(common_name = dplyr::case_when(alpha_2 == "BN" ~ "Brunei",
                                               alpha_2 == "CD" ~ "Democratic Republic of Congo",
                                               alpha_2 == "CG" ~ "Congo Republic",
                                               alpha_2 == "FK" ~ "Falkland Islands",
                                               alpha_2 == "FM" ~ "Micronesia",
                                               alpha_2 == "PS" ~ "Palestine",
                                               alpha_2 == "VA" ~ "Vatican City",
                                               .default = common_name)) |>
  # extend with unofficial information
  dplyr::add_row(alpha_2 = "XK",
                 alpha_3 = "XKS",
                 numeric = NA_character_,
                 name = "Kosovo, Republic of",
                 official_name = "Republic of Kosovo",
                 common_name = "Kosovo") |>
  # assemble complete name vars
  dplyr::mutate(name_short = common_name %|% name,
                name_long = official_name %|% name) |>
  dplyr::arrange(alpha_2) |>
  # ensure there are no duplicates
  assertr::assert(predicate = assertr::is_uniq,
                  alpha_2,
                  alpha_3,
                  name_short,
                  name_long) |>
  assertr::assert(predicate = \(x) assertr::is_uniq(x, allow.na = TRUE),
                  numeric)
```

### `data_iso_3166_2`

TODO:

-   Install older ISOcodes pkg versions and check whether codes were deleted meanwhile; if so, add them!

NOTES:

-   By design, we don't have any codes for subnational entities that ceased to exist before [ISO 3166-2](https://en.wikipedia.org/wiki/ISO_3166-2) was first
    published in 1998. In such cases, we assign `CUSTOM-` codes.

-   Due to lack of official revocation information in ISO 3166-2, we construct our own (delayed) `valid_from` and `valid_to` date columns based on detected
    changes in `ISOcodes::ISO_3166_2`. Ideally, these dates would be added to the
    [`iso_3166-2.json`](https://salsa.debian.org/iso-codes-team/iso-codes/-/blob/main/data/iso_3166-2.json) source file gathered from officially anounced
    [changes](https://en.wikipedia.org/wiki/ISO_3166-2#Changes).

```{r}
# TEMP
data_iso_3166_2 <-
  rdb:::data_iso_3166_2 |>
  dplyr::mutate(valid_from = clock::date_parse("0000-01-01"),
                valid_to = as.Date(NA))

data_iso_3166_2 <-
  rdb:::data_iso_3166_2 |>
  dplyr::filter(!(code %in% ISOcodes::ISO_3166_2$Code)) |>
  tidyr::replace_na(replace = list(valid_to = clock::date_today(zone = "UTC")))

data_iso_3166_2 <-
  ISOcodes::ISO_3166_2 |>
  tibble::as_tibble() |>
  # convert column names to snake_case
  dplyr::rename_with(.cols = everything(),
                     .fn = snakecase::to_snake_case) |>
  dplyr::mutate(valid_from = clock::date_today(zone = "UTC") - 1L,
                valid_to = as.Date(NA)) |>
  dplyr::relocate(code_parent = parent,
                  .after = code) |>
  # add expired codes
  dplyr::bind_rows(data_iso_3166_2) |>
  # ensure there are no duplicates
  assertr::assert(predicate = assertr::is_uniq,
                  code) |>
  dplyr::arrange(code)
```

### `data_iso_3166_3`

```{r}
data_iso_3166_3 <-
  ISOcodes::ISO_3166_3 |>
  tibble::as_tibble() |>
  # convert column names to snake_case
  dplyr::rename_with(.cols = everything(),
                     .fn = snakecase::to_snake_case) |>
  dplyr::mutate(alpha_2_old = stringr::str_sub(string = alpha_4,
                                               end = 2L),
                alpha_2_new = stringr::str_sub(string = alpha_4,
                                               start = 3L),
                # variation of `alpha_2_new` that in case of multiple successor countries (*HH/*XX) holds the biggest one (1. population-, then 2. area-wise)
                # (main purpose is to be able to match with UN M49 area codes)
                alpha_2_new_main = purrr::map_chr(alpha_4,
                                                  \(x) {
                                                    if (stringr::str_detect(x, "(HH|XX)$")) {
                                                      return(switch(x,
                                                             ANHH = "CW",
                                                             CSHH = "CZ",
                                                             CSXX = "RS",
                                                             FQHH = "AQ",
                                                             GEHH = "KI",
                                                             NTHH = "IQ",
                                                             PCHH = "FM",
                                                             SUHH = "RU",
                                                             cli::abort(paste0("No ISO 3166-3 alpha-4 \"n-to-1\" ISO 3166-1 alpha-2 conversion rule defined ",
                                                                               "for {.val x}. Please update {.var data_iso_3166_3} accordingly and run ",
                                                                               "again."))))
                                                    } else {
                                                      return(stringr::str_sub(x, start = 3L))
                                                    }
                                                  }),
                date_withdrawn =
                  date_withdrawn |>
                  purrr::map(\(x) {
                    if (nchar(x) == 4L) {
                      clock::date_build(year = as.integer(x))
                    } else {
                      clock::date_parse(x, format = "%F")
                    }
                  }) |>
                  purrr::reduce(c)) |>
  dplyr::relocate(alpha_2_old, alpha_2_new, alpha_2_new_main,
                  .after = alpha_3) |>
  # harmonize name style
  dplyr::mutate(name_short = dplyr::case_match(alpha_4,
                                               "BYAA" ~ "Byelorussian SSR",
                                               "FXFR" ~ "Metropolitan France",
                                               .default = stringr::str_extract(string = name,
                                                                               pattern = "[^,]+")),
                name_long = dplyr::case_match(alpha_4,
                                              "BYAA" ~ "Byelorussian Soviet Socialist Republic",
                                              "CSHH" ~ name,
                                              "SUHH" ~ "Union of Soviet Socialist Republics (USSR)",
                                              "YDYE" ~ "Democratic Yemen, People's Democratic Republic of Yemen",
                                              .default = stringr::str_replace(string = name,
                                                                              pattern = "^([^,]+), (.+)$",
                                                                              replacement = "\\2 \\1"))) |>
  dplyr::arrange(alpha_2_old,
                 alpha_2_new_main) |>
  # ensure there are no duplicates
  assertr::assert(predicate = assertr::is_uniq,
                  alpha_4,
                  alpha_3)
```

### `data_iso_639_1`

```{r}
data_iso_639_1 <-
  ISOcodes::ISO_639_2 |>
  tibble::as_tibble() |>
  # convert column names to snake_case
  dplyr::rename_with(.cols = everything(),
                     .fn = snakecase::to_snake_case) |>
  dplyr::filter(!is.na(alpha_2)) |>
  dplyr::select(code = alpha_2,
                name) |>
  dplyr::arrange(code) |>
  # ensure there are no duplicates or NAs
  assertr::assert(predicate = assertr::is_uniq,
                  code,
                  name) |>
  assertr::assert(predicate = assertr::not_na,
                  code,
                  name)
```

## `data_municipalities`

TODO:

-   Add more countries which have an [official municipality identifier](https://en.wikipedia.org/wiki/Community_Identification_Number).

    -   `AT`: [Ã–STAT-Nr](https://de.wikipedia.org/wiki/Amtlicher_Gemeindeschl%C3%BCssel#%C3%96sterreich)
    -   `DE`: [Amtlicher GemeindeschlÃ¼ssel (AGS)](https://de.wikipedia.org/wiki/Amtlicher_Gemeindeschl%C3%BCssel#Deutschland)
    -   `FR`: [INSEE code](https://en.wikipedia.org/wiki/INSEE_code)
    -   `GB`
        -   UK municipalities don't seem to have an "official municipality identifier" as such, but it appears we can resort to the [phone dialling
            codes](https://en.wikipedia.org/wiki/List_of_dialling_codes_in_the_United_Kingdom#List_of_dialling_codes). That dialling codes do not exactly
            correspond to political boundaries shouldn't matter as long as we can identify each relevant municipality.
        -   UN/LOCODE for London [is `GB LON`](https://service.unece.org/trade/locode/gb.htm).

NOTES:

-   Unfortunately, there is no ISO code standard for municipalities or any other standard with full coverage of all municipalities worldwide. We resort to the
    *UN/LOCODE*, the [United Nations Code for Trade and Transport Locations](https://en.wikipedia.org/wiki/UN/LOCODE), as the best available global municipality
    identifier. UN/LOCODE covers more than just municipalities, including entities like seaports, rail and road terminals, airports or border crossing points â€“
    we just use the subset of codes referring to municipalities. Not all municipalities worldwide have received a UN/LOCODE (yet), so we can't use it as primary
    key for the coresponding SQL table in the RDB (`municipalities`).

    We rely on the [`un-locode`](https://github.com/datasets/un-locode) dataset that is part of [DataHub's core data](https://datahub.io/docs/core-data). It's a
    regularly updated, structured JSON representation of the official [UNECE data](https://unece.org/trade/uncefact/unlocode). Column descriptions are found
    [here](https://service.unece.org/trade/locode/Service/LocodeColumn.htm).

    There is also an [official JSON-LD API](https://vocabulary.uncefact.org/unlocode-about). But since it doesn't include the change date, we rely on the
    unofficial `un-locode` dataset mentioned above. To retrieve the main dataset from the JSON-LD API, run:

    ``` r
    httr2::request(base_url = "https://vocabulary.uncefact.org/unlocode") |>
      httr2::req_headers(Accept = "application/ld+json") |>
      httr2::req_retry(max_tries = 3L) |>
      httr2::req_perform() |>
      httr2::resp_body_json(simplifyVector = TRUE)
    ```

    Note that there [appear to be duplicates in the source data, i.e. territories that have multiple LOCODEs
    assigned](https://github.com/uncefact/vocab-locode/issues/11). The underlying reason is currently unknown to us. Since there are duplicates that *only*
    differ in the LOCODE itself (i.e. all other columns are identical), we can't resolve them programmatically. Instead, we have to explicitly remove the
    affected entries and just validate that there are no more duplicates in the resulting subset we actually use (`data_municipalities`). To inspect potential
    duplicates, run:

    ``` r
    data_un_locode |>
      dplyr::group_by(country_code, subnational_entity_code, name) |>
      dplyr::summarise(n = dplyr::n()) |>
      dplyr::filter(n > 1L)
    ```

-   Additionally, we store the [official municipality identifier](https://en.wikipedia.org/wiki/Community_Identification_Number) assigned by the national
    authorities as `id_official`, *if available*. `id_official` is expected to be unique *per country*. If no suitable official identifier exists, we assign
    `CUSTOM-` with a simple serial number suffix.

    So far, we included official municipality identifiers for the following countries:

    -   [Switzerland](https://en.wikipedia.org/wiki/Community_Identification_Number#Switzerland)

-   As unique identifier we create our own one consisting of `{country_code}_{id_official}_{valid_from}`. It serves as primary key for the `municipalities` SQL
    table.

```{r}
# CH
## define function to recursively determine root entity (= subnational entity = canton)
## NOTE: this is inefficient by design
## TODO: add an optimized and polished version of this fn to pkg swissmuni?
derive_subnational_entity_code <- function(id) {
  
  parent <-
    data_municipalities |>
    dplyr::filter(Identifier == !!id) |>
    # choose most recent entry in case of multiple ones
    tidyr::replace_na(replace = list(ValidTo = clock::date_today(zone = "UTC") + 1L)) |>
    dplyr::filter(ValidTo == max(ValidTo)) |>
    # this is necessary to filter out Identifiers that are assigned more than once (god knows why)
    dplyr::filter(Level == min(Level))
  
  if (nrow(parent) == 0L) {
    cli::cli_alert_warning("No parent entry found for entity with OFS code {.val {id}}.")
    return(NA_character_)
    
  } else if (nrow(parent) > 1L) {
    cli::cli_alert_warning("Multiple parent entries found for entity with OFS code {.val {id}}.")
    return(NA_character_)
  }
  
  # abort recursion if no more parent
  if (is.na(parent$Parent)) {
    
    result <-
      BFS::register_kt |>
      dplyr::filter(KTNR == !!parent$Identifier) |>
      dplyr::pull(GDEKT) %>%
      paste0("CH-", .)
    
  } else {
    result <- derive_subnational_entity_code(parent$Parent)
  }
  
  result
}

data_municipalities <- swissmuni::snapshots(start_date = "0000-01-01",
                                            end_date = clock::date_today(zone = "UTC"))
data_municipalities %<>%
  # reduce to only municipalities
  dplyr::filter(Level == 3L) %>%
  # add `country_code` and derive `subnational_entity_code`
  dplyr::mutate(country_code = "CH",
                subnational_entity_code = purrr::map_chr(Parent,
                                                         derive_subnational_entity_code)) %>%
  # tidy cols
  dplyr::select(country_code,
                subnational_entity_code,
                id_official = CODE_OFS_1_Text_en,
                name = Name_en,
                valid_from = ValidFrom,
                valid_to = ValidTo)

# add our municipality ID
data_municipalities %<>% dplyr::mutate(id = paste(country_code, id_official, valid_from,
                                                  sep = "_"),
                                       .before = 1L)
# add UN/LOCODEs
data_un_locode <-
  readr::read_csv(file = "https://raw.githubusercontent.com/datasets/un-locode/main/data/code-list.csv",
                  col_types = "c") |>
  dplyr::rename_with(.cols = everything(),
                     .fn = snakecase::to_snake_case) |>
  dplyr::mutate(country_code = country,
                subnational_entity_code = dplyr::if_else(is.na(country_code) | is.na(subdivision),
                                                         NA_character_,
                                                         paste(country_code, subdivision,
                                                               sep = "-")),
                un_locode = dplyr::if_else(is.na(country_code) | is.na(location),
                                           NA_character_,
                                           paste(country_code, location)),
                # NOTE: contrary to what one would expect, there are actually diacritics present in the municipality names of multiple countries incl. CZ,
                #       HR, JP, VN and more, so we ASCII-fy the names ourselves
                name_ascii = stringi::stri_trans_general(str = name_wo_diacritics,
                                                         id = "Latin-ASCII"),
                # apparently, the original date format is `%y%m`, i.e. has no day component
                updated_at = clock::date_parse(x = ifelse(is.na(date),
                                                          date,
                                                          paste0(date, "01")),
                                               format = "%y%m%d"),
                .before = 1L) |>
  dplyr::relocate(name,
                  .before = name_ascii) |>
  dplyr::select(-c(country, date, location, name_wo_diacritics, subdivision)) |>
  # filter out all entries without a country code
  dplyr::filter(!is.na(un_locode)) |>
  # remove duplicates, see NOTES above
  ## CH SchÃ¶nenbuch: we keep `CH SOH` which was created first
  dplyr::filter(un_locode != "CH SBC")

data_municipalities <-
  data_un_locode |>
  dplyr::filter(country_code == "CH") |>
  dplyr::select(subnational_entity_code, un_locode, name) |>
  dplyr::left_join(x = data_municipalities,
                   by = c("name", "subnational_entity_code"),
                   relationship = "many-to-one") |>
  dplyr::relocate(un_locode,
                  .after = id_official)

# arrange sensibly
data_municipalities %<>% dplyr::arrange(country_code,
                                        stringr::str_rank(id_official,
                                                          numeric = TRUE),
                                        valid_from)
```

## `country_codes_sudd_invalid`

```{r}
country_codes_sudd_invalid <- c("MB", "ZZ")

# ensure they aren't used in ISO 3166
if (any(country_codes_sudd_invalid %in% c(data_iso_3166_1$alpha_2,
                                          data_iso_3166_3$alpha_2_old,
                                          data_iso_3166_3$alpha_2_new_main))) {
  
  cli::cli_abort("At least one of {.var country_codes_sudd_invalid} is used in regular ISO 3166 alpha-2 codes. Please investigate.")
}
```

## `data_topics`

```{r}
data_topics <-
  # download file from private CCM Design repo
  yay::gh_text_file(owner = "zdaarau",
                    name = "c2d-app",
                    rev = "master",
                    path = "ch.c2d/web/themes.json") |>
  jsonlite::fromJSON(flatten = FALSE) |>
  tibble::as_tibble() |>
  # create tidy data version
  dplyr::rename(topic_tier_1 = name,
                topic_tier_2 = children) |>
  tidyr::unnest(cols = topic_tier_2,
                keep_empty = TRUE) |>
  dplyr::rename(topic_tier_2 = name,
                topic_tier_3 = children) |>
  # ensure consistent col subtypes
  dplyr::mutate(topic_tier_3 = purrr::map(topic_tier_3,
                                          \(x) { if (is.list(x)) character() else x })) |>
  tidyr::unnest(cols = topic_tier_3,
                keep_empty = TRUE)
```

## `months_de*`

```{r}
months_de <-
  1:12 |>
  magrittr::set_names(clock::clock_labels_lookup("de")$month) |>
  as.list()

months_de_fms <- rdb:::as_fm_list(months_de)
```

## `pg_metadata_*`

```{r}
rdb:::tbl_metadata$name |>
  purrr::walk(\(tbl_name) assign(x = paste0("pg_metadata_", tbl_name),
                                 value = rdb:::pg_col_metadata(tbl_name = tbl_name),
                                 pos = globalenv()))
```

## `pkg_config`

```{r}
pkg_config <-
  tibble::tibble(key = character(),
                 default_value = list(),
                 default_value_dynamic = character(),
                 require = logical(),
                 description = character()) |>
  tibble::add_row(key = "pg_host",
                  default_value = list("ep-frosty-flower-a28keh10.eu-central-1.aws.neon.tech"),
                  description = paste0("RDB PostgreSQL (neon.tech) host address. Defaults to a [read ",
                                       "replica](https://neon.tech/docs/introduction/read-replicas) which has no write access to the database."),
                  require = TRUE) |>
  tibble::add_row(key = "pg_user",
                  default_value = list("r_anon"),
                  description = paste0("RDB PostgreSQL username for database operations performed via this package. To be able to edit the database, the user ",
                                       "must have sufficient privileges. Defaults to the read-only user `r_anon`."),
                  require = TRUE) |>
  tibble::add_row(key = "pg_password",
                  default_value = list("WTYUeDtTm0UV4nXzTZ7morHSdM0wQh0p"),
                  description = "Password for `pg_user`. Defaults to the password for the read-only user `r_anon`.",
                  require = TRUE) |>
  tibble::add_row(key = "pg_roles_csv_file",
                  description = paste0("File path to a UTF-8 encoded CSV file containing the columns `role` and `password` describing additional roles on the ",
                                       "RDB PostgreSQL server. Required for [rdb::pg_init_db()] and others."),
                  require = TRUE) |>
  tibble::add_row(key = "nocodb_email",
                  description = "E-mail address of the [RDB NocoDB server](https://admin.rdb.vote/)'s super admin user. Required for [rdb::reset_nocodb()].",
                  require = TRUE) |>
  tibble::add_row(key = "nocodb_password",
                  description = "Password of the [RDB NocoDB server](https://admin.rdb.vote/)'s super admin user Required for [rdb::reset_nocodb()].",
                  require = TRUE) |>
  tibble::add_row(key = "nocodb_user_account_csv_file",
                  description = paste0("File path to a UTF-8 encoded CSV file containing the columns `name`, `email` and `password` describing additional user",
                                       " accounts to create on the [RDB NocoDB server](https://admin.rdb.vote/) via ",
                                       "[rdb::reset_nocodb()]."),
                  require = FALSE) |>
  tibble::add_row(key = "nocodb_b2_access_key",
                  description = "Access key ID of the `rdb-attachments` Backblaze B2 bucket. Required for [rdb::reset_nocodb()].",
                  require = TRUE) |>
  tibble::add_row(key = "nocodb_b2_access_secret",
                  description = "Access secret of the `rdb-attachments` Backblaze B2 bucket. Required for [rdb::reset_nocodb()].",
                  require = TRUE) |>
  tibble::add_row(key = "global_max_cache_age",
                  default_value = list("30 days"),
                  description = pkgsnip::md_snip("opt_global_max_cache_age"),
                  require = TRUE)
```

## `rfrnd_cols_order`

```{r}
rfrnd_cols_order <- data_codebook$variable_name
i_loop <- 0

for (i in which(data_codebook$variable_name != data_codebook$variable_name_unnested)) {
  
  rfrnd_cols_order %<>% append(values = data_codebook$variable_name_unnested[i],
                               after = i + i_loop)
  i_loop <- i_loop + 1L
}
```

## `topics_tier_#_`

Only for performance-reasons.

```{r}
topics_tier_1_ <- rdb::topics(tiers = 1L)
topics_tier_2_ <- rdb::topics(tiers = 2L)
topics_tier_3_ <- rdb::topics(tiers = 3L)
```

## `un_regions`

NOTES:

-   Antarctica (AQ) is not part of any UN subregion (i.e. it's [directly below
    *World*](https://en.wikipedia.org/wiki/List_of_countries_by_United_Nations_geoscheme)).

```{r}
# compile `country_code` <-> `un_country_code` dict
codes <-
  data_iso_3166_1 |>
  # temporarily add ISO 3166-1 alpha-3 codes for matching with M49 codes
  dplyr::select(country_code = alpha_2,
                alpha_3) |>
  # temporarily add M49 code for matching with actual UN region codes and names
  dplyr::left_join(y = ISOcodes::UN_M.49_Countries |> dplyr::select(un_country_code = Code,
                                                                    alpha_3 = ISO_Alpha_3),
                   by = "alpha_3") |>
  dplyr::select(-alpha_3) |>
  # manual corrections
  dplyr::mutate(
    # certain countries share the same UN country code / don't have their own one for stupid political reasons (like China & Taiwan or Serbia & Kosovo), thus we
    # assign M49 code of
    # - China to Taiwan, cf. https://en.wikipedia.org/wiki/United_Nations_geoscheme_for_Asia#Note_on_Taiwan
    # - Serbia to Kosovo, cf. https://en.wikipedia.org/wiki/XK_(user_assigned_code)#Potential_assignment_of_an_official_ISO_3166-1_code_for_Kosovo
    un_country_code = dplyr::case_when(country_code == "TW" ~ "156",
                                       country_code == "XK" ~ "688",
                                       .default = un_country_code)
  ) |>
  # ensure there are no NAs left
  assertr::assert(predicate = assertr::not_na,
                  un_country_code)

# extract UN regions of the 3 different tiers
un_regions_tier_1 <-
  ISOcodes::UN_M.49_Regions |>
  tibble::as_tibble() |>
  dplyr::filter(Type == "Region" & Parent == "001") |>
  tidyr::separate_longer_delim(cols = Children,
                               delim = ", ") |>
  dplyr::mutate(un_region_tier_1_name = Name,
                un_region_tier_1_code = Code,
                children_tier_1 = Children,
                .keep = "none")

un_regions_tier_2 <-
  ISOcodes::UN_M.49_Regions |>
  tibble::as_tibble() |>
  dplyr::filter(Type == "Region" & Parent %in% un_regions_tier_1$un_region_tier_1_code) |>
  tidyr::separate_longer_delim(cols = Children,
                               delim = ", ") |>
  dplyr::mutate(un_region_tier_2_name = Name,
                un_region_tier_2_code = Code,
                children_tier_2 = Children,
                .keep = "none")

un_regions_tier_3 <-
  ISOcodes::UN_M.49_Regions |>
  tibble::as_tibble() |>
  dplyr::filter(Type == "Region" & Parent %in% un_regions_tier_2$un_region_tier_2_code) |>
  tidyr::separate_longer_delim(cols = Children,
                               delim = ", ") |>
  dplyr::mutate(un_region_tier_3_name = Name,
                un_region_tier_3_code = Code,
                children_tier_3 = Children,
                .keep = "none")

# combine UN regions of different tiers into single dataset and add `country_code`
un_regions <-
  un_regions_tier_1 |>
  dplyr::full_join(y = un_regions_tier_2,
                   by = dplyr::join_by(children_tier_1 == un_region_tier_2_code),
                   relationship = "one-to-many") |>
  dplyr::full_join(y = un_regions_tier_3,
                   by = dplyr::join_by(children_tier_2 == un_region_tier_3_code),
                   relationship = "one-to-many") |>
  dplyr::mutate(un_region_tier_2_code = dplyr::if_else(is.na(un_region_tier_2_name),
                                                       NA_character_,
                                                       children_tier_1),
                un_region_tier_3_code = dplyr::if_else(is.na(un_region_tier_3_name),
                                                       NA_character_,
                                                       children_tier_2),
                un_country_code = dplyr::if_else(is.na(children_tier_3),
                                                 children_tier_2,
                                                 children_tier_3),
                # add UN subregion which, except for Northern Europe, corresponds to the lowest `un_region_tier_*_name`
                un_subregion = dplyr::if_else(un_region_tier_1_name != "Europe",
                                              un_region_tier_3_name %|% un_region_tier_2_name,
                                              un_region_tier_2_name)) |>
  dplyr::select(un_country_code,
                starts_with("un_region_tier_1_"),
                starts_with("un_region_tier_2_"),
                starts_with("un_region_tier_3_"),
                un_subregion) |>
  dplyr::left_join(y = codes,
                   by = "un_country_code",
                   # NOTE: we must allow multiple matches because of the manual "corrections" in `codes` above
                   relationship = "one-to-many") |>
  dplyr::relocate(country_code) |>
  # remove rows without `country_code` (Sark)
  dplyr::filter(!is.na(country_code)) |>
  # ensure there are no NAs left
  assertr::assert(predicate = assertr::not_na,
                  un_country_code) |>
  # convert UN cols to type fct
  dplyr::mutate(
    # tier-1 name lvls are ordered alphabetically
    un_region_tier_1_name = factor(x = un_region_tier_1_name,
                                   levels = sort(unique(un_region_tier_1_name))),
    # tier-2 name lvls are ordered by tier-1 name, then ~ clockwise cardinal direction
    un_region_tier_2_name = factor(x = un_region_tier_2_name,
                                   levels = c(
                                     # Africa
                                     "Northern Africa",
                                     "Sub-Saharan Africa",
                                     # Americas
                                     "Northern America",
                                     "Latin America and the Caribbean",
                                     # Asia
                                     "Central Asia",
                                     "Eastern Asia",
                                     "South-eastern Asia",
                                     "Southern Asia",
                                     "Western Asia",
                                     # Europe
                                     "Northern Europe",
                                     "Eastern Europe",
                                     "Southern Europe",
                                     "Western Europe",
                                     # Oceania
                                     "Micronesia",
                                     "Polynesia",
                                     "Australia and New Zealand",
                                     "Melanesia")),
    # tier-3 name lvls are ordered by tier-2 name, then ~ clockwise cardinal direction
    un_region_tier_3_name = factor(x = un_region_tier_3_name,
                                   levels = c(
                                     # Africa
                                     "Middle Africa",
                                     "Eastern Africa",
                                     "Southern Africa",
                                     "Western Africa",
                                     # Americas
                                     "Caribbean",
                                     "South America",
                                     "Central America",
                                     # Europe
                                     "Channel Islands")),
    # subregion lvls inherit the order of tier-2 and -3 names
    un_subregion = factor(x = un_subregion,
                          levels = c(
                            # Africa
                            "Northern Africa",
                            "Eastern Africa",
                            "Southern Africa",
                            "Middle Africa",
                            "Western Africa",
                            # Americas
                            "Northern America",
                            "Caribbean",
                            "South America",
                            "Central America",
                            # Asia
                            "Central Asia",
                            "Eastern Asia",
                            "South-eastern Asia",
                            "Southern Asia",
                            "Western Asia",
                            # Europe
                            "Northern Europe",
                            "Eastern Europe",
                            "Southern Europe",
                            "Western Europe",
                            # Oceania
                            "Micronesia",
                            "Polynesia",
                            "Australia and New Zealand",
                            "Melanesia")),
    # code lvls are simply in ascending order
    un_country_code = factor(x = un_country_code,
                             levels = sort(unique(ISOcodes::UN_M.49_Countries$Code))),
    dplyr::across(.cols = matches("un_region_tier_\\d+_code"),
                  .fns = ~ factor(x = .x,
                                  levels = sort(unique(.x))))
  )
```

## `val_set`

```{r}
val_set                        <- list()
val_set$country_code           <- c(data_iso_3166_1$alpha_2,
                                    data_iso_3166_3$alpha_4)
val_set$country_code_long      <- sort(unique(c(data_iso_3166_1$alpha_3,
                                                data_iso_3166_3$alpha_3)))
val_set$country_code_continual <- sort(unique(data_iso_3166_1$alpha_2,
                                              data_iso_3166_3$alpha_2_new_main))
val_set$country_name           <- sort(unique(c(data_iso_3166_1$name_short,
                                                data_iso_3166_3$name_short)))
val_set$country_name_long      <- sort(unique(c(data_iso_3166_1$name_long,
                                                data_iso_3166_3$name_long)))
```

## `var_lbls`

Only for performance-reasons.

```{r}
var_lbls <-
  data_codebook$variable_label |>
  pal::strip_md() |>
  as.list() |>
  magrittr::set_names(value = data_codebook$variable_name)
```

# Write data

Save all the small data objects as a single internal file `R/sysdata.rda`. Note that when documenting them, they must be explicitly `@export`ed to be available
to package users.

```{r}
usethis::use_data(col_names_nocodb_filled,
                  col_names_un,
                  country_codes_sudd_invalid,
                  data_codebook,
                  data_iso_3166_1,
                  data_iso_3166_2,
                  data_iso_3166_3,
                  data_iso_639_1,
                  data_municipalities,
                  data_topics,
                  months_de,
                  months_de_fms,
                  pg_metadata_countries,
                  pg_metadata_subnational_entities,
                  pg_metadata_municipalities,
                  pg_metadata_languages,
                  pg_metadata_actors,
                  pg_metadata_options,
                  pg_metadata_referendum_types,
                  pg_metadata_legal_norms,
                  pg_metadata_referendum_types_legal_norms,
                  pg_metadata_referendums,
                  pg_metadata_referendum_titles,
                  pg_metadata_referendum_questions,
                  pg_metadata_referendum_positions,
                  pg_metadata_referendum_votes,
                  pg_metadata_referendum_sub_votes,
                  pkg_config,
                  rfrnd_cols_order,
                  topics_tier_1_,
                  topics_tier_2_,
                  topics_tier_3_,
                  un_regions,
                  val_set,
                  var_lbls,
                  internal = TRUE,
                  overwrite = TRUE,
                  compress = "xz",
                  version = 3L)
```

# Remind to regenerate RDB tables if necessary

```{r}
if (pal::desc_dep_vrsn(pkg = "ISOcodes") < max(as.numeric_version(pal::ls_pkg(pkg = "ISOcodes")$Version))) {
  
  cli::cli_alert_warning(paste0("New ISOcodes package version in use. Please run {.run {paste0('rdb::', c('update_countries()', 'update_langs()', ",
                                "'update_subnational_entities()', 'use_pkg(\"ISOcodes\", type = \"s\")'))}} after rebuilding the {.pkg rdb} package."))
}
```

# Update ISRG Root X1 certificate

NOTES:

-   We just blindly copy over the root certificate from the system if it exists and user=salim. This ensures the certificate is updated before it expires.

```{r}
path_sys_root_cert <- "/usr/share/ca-certificates/mozilla/ISRG_Root_X1.crt"

if (Sys.info()[["user"]] == "salim" && fs::file_exists(path_sys_root_cert)) {
  
  fs::file_copy(path = path_sys_root_cert,
                new_path = "inst/certs/ISRG_Root_X1.crt",
                overwrite = TRUE)
}
```
